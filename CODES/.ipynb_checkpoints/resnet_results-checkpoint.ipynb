{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0033fb-bd9f-4a29-bed9-054809a30b41",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "### The saved predictions are used to calculate the evaluation metrics and assess the model. The evaluaiton metrics used are\n",
    "* Mean Absolute Error (MAE)\n",
    "* Mean Square Error (MSE)\n",
    "* Root Mean Square Error (RMSE)\n",
    "* R-Squared\n",
    "\n",
    "#### Finally the plots of the Actual values vs. Predicted values are also shown for all crime types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700f146-fcb2-49e8-aa5a-6103f5785831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c8e52-b789-433e-b70c-7cdb30b9fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to root directory of the project \n",
    "os.chdir(\"/data/private/THESIS/\")\n",
    "base_path = os.getcwd()\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8a7cb-81b2-4113-8792-9bbf6d20de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(dataframe,col_list):\n",
    "    ''' Takes the dataframe with actual and predicted value columns as input and return the evaulation \n",
    "        metrics MAE, MSE, RMSE and R-squared as a dataframe.\n",
    "        Parameters:\n",
    "        datframe: Pandas dataframe with actual and predicted values columns.\n",
    "        col_list: Columns in the dataframe for which the evaluation has to be done.'''\n",
    "    \n",
    "    dic = {}\n",
    "    for i in col_list:\n",
    "        error = dataframe[i] - dataframe[i+\"_p\"]\n",
    "        error_sq = error*error\n",
    "        mse = error_sq.mean()\n",
    "        rmse = math.sqrt(mse)\n",
    "        mae = abs(error).mean()\n",
    "        r2 = r2_score(dataframe[i],dataframe[i+\"_p\"])\n",
    "        dic[i] = {'mse':mse,'rmse':rmse,'mae':mae,'r2':r2}\n",
    "    error_df = pd.DataFrame(dic)\n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f5bce-7f2c-4fc6-98d6-c66205ab8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file obtained after the prediction\n",
    "final_df = pd.read_csv(\"FILES/resnet18_44_tr_v1.0_scaled_ds.csv\")\n",
    "col_list = [\"burglary\",\"robbery\",\"o_crimes\",\"v_crimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dde158-532c-4db0-90a1-eb8c1214638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the evaluation metrics per point\n",
    "f1 = calculate_accuracy(final_df,col_list)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643387c-556c-4191-8bf7-8ac7c112c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of actual vs. predicted values\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].scatter(final_df['burglary'], final_df['burglary_p'])\n",
    "ax[0,0].set_title('Burglary')\n",
    "ax[0,1].scatter(final_df['robbery'], final_df['robbery_p'])\n",
    "ax[0,1].set_title('Robbery')\n",
    "ax[1,0].scatter(final_df['o_crimes'], final_df['o_crimes_p'])\n",
    "ax[1,0].set_title('Other Thefts')\n",
    "ax[1,1].scatter(final_df['v_crimes'], final_df['v_crimes_p'])\n",
    "ax[1,1].set_title('Vehicle Crimes')\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='Actual', ylabel='Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4030744-92f7-4a02-a140-37ba391bcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the records per cell and take mean\n",
    "d = {'burglary':'mean','burglary_p':'mean','robbery':'mean','robbery_p':'mean','o_crimes':'mean','o_crimes_p':'mean','v_crimes':'mean','v_crimes_p':'mean'}\n",
    "agg_df = final_df.groupby('pointid').agg(d)\n",
    "\n",
    "# Calculate the evaluation metrics per cell\n",
    "f2 = calculate_accuracy(agg_df,col_list)\n",
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56482e-e1f3-4a82-87ac-7e96f23d0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of actual vs. predicted values\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].scatter(agg_df['burglary'], agg_df['burglary_p'])\n",
    "# ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax[0,0].set_title('Burglary')\n",
    "ax[0,1].scatter(agg_df['robbery'], agg_df['robbery_p'])\n",
    "ax[0,1].set_title('Robbery')\n",
    "ax[1,0].scatter(agg_df['o_crimes'], agg_df['o_crimes_p'])\n",
    "ax[1,0].set_title('Other Thefts')\n",
    "ax[1,1].scatter(agg_df['v_crimes'], agg_df['v_crimes_p'])\n",
    "ax[1,1].set_title('Vehicle Crimes')\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='Actual', ylabel='Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
